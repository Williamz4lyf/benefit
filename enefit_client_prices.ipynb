{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enefit - Predict Energy Behavior of Prosumers\n",
    "\n",
    "The challenge in this competition is to predict the amount of electricity produced and consumed by Estonian energy customers who have installed solar panels. The dataset includes weather data, the relevant energy prices, and records of the installed photovoltaic capacity.\n",
    "\n",
    "This is a forecasting competition using the time series API.\n",
    "\n",
    "**Description**\n",
    "\n",
    "The number of prosumers is rapidly increasing, and solving the problems of energy imbalance and their rising costs is vital. If left unaddressed, this could lead to increased operational costs, potential grid instability, and inefficient use of energy resources. If this problem were effectively solved, it would significantly reduce the imbalance costs, improve the reliability of the grid, and make the integration of prosumers into the energy system more efficient and sustainable. Moreover, it could potentially incentivize more consumers to become prosumers, knowing that their energy behavior can be adequately managed, thus promoting renewable energy production and use.\n",
    "\n",
    "**About us**\n",
    "\n",
    "Enefit is one of the biggest energy companies in Baltic region. As experts in the field of energy, we help customers plan their green journey in a personal and flexible manner as well as implement it by using environmentally friendly energy solutions.\n",
    "\n",
    "At present, Enefit is attempting to solve the imbalance problem by developing internal predictive models and relying on third-party forecasts. However, these methods have proven to be insufficient due to their low accuracy in forecasting the energy behavior of prosumers. The shortcomings of these current methods lie in their inability to accurately account for the wide range of variables that influence prosumer behavior, leading to high imbalance costs. By opening up the challenge to the world's best data scientists through the Kaggle platform, Enefit aims to leverage a broader pool of expertise and novel approaches to improve the accuracy of these predictions and consequently reduce the imbalance and associated costs.\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "Submissions are evaluated on the Mean Absolute Error (MAE) between the predicted return and the observed target. The formula is given by:\n",
    "\n",
    "ùëÄùê¥ùê∏=1ùëõ‚àëùëñ=1ùëõ|ùë¶ùëñ‚àíùë•ùëñ|\n",
    "MAE = 1n‚àëi=1n|yi-xi|\n",
    "\n",
    "Where:\n",
    "* ùëõ is the total number of data points.\n",
    "* ùë¶ùëñ is the predicted value for data point i.\n",
    "* ùë•ùëñ is the observed value for data point i.\n",
    "\n",
    "**Submitting**\n",
    "\n",
    "You must submit to this competition using the provided python time-series API, which ensures that models do not peek forward in time. To use the API, follow the template in this [notebook](https://www.kaggle.com/code/sohier/enefit-basic-submission-demo).\n",
    "\n",
    "**Timeline**\n",
    "\n",
    "This is a future data prediction competition with an active training phase and a second period where selected submissions will be evaluated against future ground truth data.\n",
    "\n",
    "*Training Timeline*\n",
    "\n",
    "* November 1, 2023 - Start Date.\n",
    "* January 24, 2024 - Entry Deadline. You must accept the competition rules before this date in order to compete.\n",
    "* January 24, 2024 - Team Merger Deadline. This is the last day participants may join or merge teams.\n",
    "* January 31, 2024 - Final Submission Deadline.\n",
    "\n",
    "All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n",
    "\n",
    "*Prediction Timeline:*\n",
    "\n",
    "Starting after the final submission deadline there will be periodic updates to the leaderboard to reflect future data updates that will be evaluated against selected submissions. We anticipate 1-3 interim updates before the final evaluation.\n",
    "\n",
    "* April 30, 2024 - Competition End Date\n",
    "\n",
    "**Prizes**\n",
    "\n",
    "* 1st Place - $ 15,000\n",
    "* 2nd Place - $ 10,000\n",
    "* 3rd Place - $ 8,000\n",
    "* 4th Place - $ 7,000\n",
    "* 5th Place - $ 5,000\n",
    "* 6th Place - $ 5,000\n",
    "\n",
    "**Code Requirements**\n",
    "\n",
    "Submissions to this competition must be made through Notebooks. In order for the \"Submit\" button to be active after a commit, the following conditions must be met:\n",
    "\n",
    "* CPU Notebook <= 9 hours run-time\n",
    "* GPU Notebook <= 9 hours run-time\n",
    "* Internet access disabled\n",
    "* Freely & publicly available external data is allowed, including pre-trained models\n",
    "* Submission file must be named submission.csv and be generated by the API.\n",
    "\n",
    "Please see the [Code Competition FAQ](https://www.kaggle.com/docs/competitions#notebooks-only-FAQ) for more information on how to submit. And review the [code debugging doc](https://www.kaggle.com/code-competition-debugging) if you are encountering submission errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime as dt\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "import opendatasets as od\n",
    "import kaggle\n",
    "import zipfile\n",
    "import io\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, STL\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from tqdm import notebook\n",
    "from itertools import product\n",
    "from typing import Union\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_zip(zip_file_path):\n",
    "    zip_files = list()\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        file_list = zip_ref.namelist()\n",
    "        for file in file_list:\n",
    "            zip_files.append(file)\n",
    "    return zip_files\n",
    "\n",
    "zip_file_path = 'predict-energy-behavior-of-prosumers.zip'\n",
    "\n",
    "enefit_files = list_files_in_zip(zip_file_path)\n",
    "enefit_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_from_zip(zip_file_path, csv_file_name):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        with zip_ref.open(csv_file_name) as file:\n",
    "            df = pd.read_csv(io.TextIOWrapper(file))\n",
    "            return df\n",
    "\n",
    "def read_json_from_zip(zip_file_path, json_file_name):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        with zip_ref.open(json_file_name) as file:\n",
    "            data = json.load(file)\n",
    "            df = pd.DataFrame(data, index=range(len(data)))\n",
    "            return df\n",
    "\n",
    "def clean_date(df):\n",
    "    date_cols = ['date', 'datetime', 'forecast_date', 'origin_date', 'forecast_datetime', 'origin_datetime']\n",
    "    for col in df.columns:\n",
    "        if col in date_cols:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enefit_dict = dict()\n",
    "keys = [\n",
    "    'client', 'electricity_prices', \n",
    "    'weather_station_to_county_mapping', 'county_id_to_name_map', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    if key + '.csv' in enefit_files:\n",
    "        csv_file_name = key + '.csv'\n",
    "        enefit_dict[key] = read_csv_from_zip(zip_file_path, csv_file_name)\n",
    "    elif key + '.json' in enefit_files:\n",
    "        json_file_name = key + '.json'\n",
    "        enefit_dict[key] = read_json_from_zip(zip_file_path, json_file_name)\n",
    "\n",
    "enefit_dict['county_id_to_name_map'] = enefit_dict['county_id_to_name_map'].iloc[0].T\n",
    "\n",
    "for key in keys[0:2]:\n",
    "    enefit_dict[key] = clean_date(enefit_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_colors = [\n",
    "    '#4C72B0', '#55A868', '#C44E52',\n",
    "    '#8172B2', '#CCB974', '#64B5CD'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Client**\n",
    "\n",
    "The features in this dataset are:\n",
    "* product_type: ID code with the following mapping of codes to contract types: {0: \"Combined\", 1: \"Fixed\", 2: \"General service\", 3: \"Spot\"}\n",
    "* county: An ID code for the county. See county_id_to_name_map.json for the mapping of ID codes to county names.\n",
    "* eic_count: The aggregated number of consumption points (EICs - European Identifier Code).\n",
    "* installed_capacity: Installed photovoltaic solar panel capacity in kilowatts.\n",
    "* is_business: Boolean for whether or not the prosumer is a business.\n",
    "* date\n",
    "* data_block_id: All rows sharing the same `data_block_id` will be available at the same forecast time. This is a function of what information is available when forecasts are actually made, at 11 AM each morning. For example, if the forecast weather `data_block_id` for predictions made on October 31st is 100 then the historic weather data_block_id for October 31st will be 101 as the historic weather data is only actually available the next day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T06:37:15.497782Z",
     "start_time": "2023-12-28T06:37:15.337189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   product_type  county  eic_count  installed_capacity  is_business  \\\n0             1       0        108              952.89            0   \n1             2       0         17              166.40            0   \n2             3       0        688             7207.88            0   \n3             0       0          5              400.00            1   \n4             1       0         43             1411.00            1   \n\n        date  data_block_id  \n0 2021-09-01              2  \n1 2021-09-01              2  \n2 2021-09-01              2  \n3 2021-09-01              2  \n4 2021-09-01              2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product_type</th>\n      <th>county</th>\n      <th>eic_count</th>\n      <th>installed_capacity</th>\n      <th>is_business</th>\n      <th>date</th>\n      <th>data_block_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>108</td>\n      <td>952.89</td>\n      <td>0</td>\n      <td>2021-09-01</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n      <td>17</td>\n      <td>166.40</td>\n      <td>0</td>\n      <td>2021-09-01</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n      <td>688</td>\n      <td>7207.88</td>\n      <td>0</td>\n      <td>2021-09-01</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>400.00</td>\n      <td>1</td>\n      <td>2021-09-01</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>43</td>\n      <td>1411.00</td>\n      <td>1</td>\n      <td>2021-09-01</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enefit_dict['client'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-28T06:39:42.081217Z",
     "start_time": "2023-12-28T06:39:41.898304Z"
    }
   },
   "outputs": [],
   "source": [
    "pc_map = {0: \"Combined\", 1: \"Fixed\", \n",
    "          2: \"General service\", 3: \"Spot\"}\n",
    "\n",
    "enefit_dict['client'] = enefit_dict['client'].assign(\n",
    "    product_type_map=lambda x: x.product_type.map(pc_map),\n",
    "    county_map=lambda x: x.county.astype(str).map(enefit_dict['county_id_to_name_map'].str.title().to_dict())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most electricity demand occurs in the spot market. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "enefit_dict['client'].product_type_map.value_counts().plot(\n",
    "    kind='barh', xlabel='Frequency', \n",
    "    ylabel='Product Type',\n",
    "    title='Distribution of Product Types',\n",
    "    ax=ax\n",
    ").invert_yaxis()\n",
    "ax.grid(alpha=.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "enefit_dict['client'].county_map.value_counts().plot(\n",
    "    kind='barh', xlabel='Frequency',\n",
    "    ylabel='County',\n",
    "    title='Distribution of Counties',\n",
    "    ax=ax\n",
    ").invert_yaxis()\n",
    "ax.grid(alpha=.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Installed Capacity**\n",
    "\n",
    "Harjumaa county has the highest total installed capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_order = enefit_dict['client'].groupby(by='county_map').agg({'installed_capacity':'sum'}).sort_values(by='installed_capacity', ascending=False).index.values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.barplot(\n",
    "    data=enefit_dict['client'],\n",
    "    x='installed_capacity',\n",
    "    y='county_map',\n",
    "    estimator='sum',\n",
    "    orient='h',\n",
    "    order=plot_order,\n",
    "    ax=ax\n",
    ")\n",
    "ax.grid(alpha=.25)\n",
    "\n",
    "ax.set_xlabel('Total Installed Capacity')\n",
    "ax.set_ylabel('Counties')\n",
    "ax.set_title('Total Installed Capacity (kW) across Counties')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most counties, installed capacity for businesses is higher than capacity for non-businesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['client'].groupby(by=['county_map', 'is_business']).installed_capacity.sum().unstack().rename(columns={0:'not_business', 1:'business'})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df.index, df.not_business, width=0.4, align='center', label='Not Business')\n",
    "plt.bar(df.index, df.business, width=0.4, align='edge', label='Business')\n",
    "\n",
    "plt.xlabel('Counties')\n",
    "plt.ylabel('Total Installed Capacity (kW)')\n",
    "plt.title('Total Installed Capacity Segmented by Business / Not Business')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(alpha=.25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most activity is in the spot market, where business clients are more popular. The second most popular market is the fixed market, where non-business clients dominate. There is nearly no activity in the general service market and the combined market services only business consumers.\n",
    "\n",
    "Developing a model to reduce energy imbalance costs will have to prioritize the spot and fixed markets, which make up nearly all products sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "g = sns.catplot(\n",
    "    data=enefit_dict['client'],\n",
    "    kind=\"bar\",\n",
    "    orient='h',\n",
    "    y='county_map',\n",
    "    x='installed_capacity',\n",
    "    hue='is_business',\n",
    "    col='product_type_map',\n",
    "    col_wrap=2,\n",
    "    height=4,\n",
    "    estimator=sum\n",
    ")\n",
    "\n",
    "g.set_axis_labels('County', 'Installed Capacity')\n",
    "g.set_titles('Product Type: {col_name}')\n",
    "\n",
    "new_labels = ['Non-business', 'Business']\n",
    "for ax in g.axes.flat:\n",
    "    handles, _ = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, new_labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Remove the previous legend\n",
    "g._legend.remove()\n",
    "\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Total Installed Capacity (kW) by Product Type & Business Segments')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drill down to general service & combined to see them clearer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['client'].query(\n",
    "    'product_type_map==\"General service\"'\n",
    ").groupby(by=['county_map', 'is_business']).installed_capacity.sum().unstack().rename(columns={0:'not_business', 1:'business'})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df.index, df.not_business, width=0.4, align='center', label='Not Business')\n",
    "plt.bar(df.index, df.business, width=0.4, align='edge', label='Business')\n",
    "\n",
    "plt.xlabel('Counties')\n",
    "plt.ylabel('Total Installed Capacity (kW)')\n",
    "plt.title('Total Installed Capacity (General service) Segmented by Business / Not Business')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=.25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['client'].query(\n",
    "    'product_type_map==\"Combined\"'\n",
    ").groupby(by=['county_map', 'is_business']).installed_capacity.sum().unstack().rename(columns={0:'not_business', 1:'business'})\n",
    "df['not_business'] = 0\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df.index, df.not_business, width=0.4, align='center', label='Not Business')\n",
    "plt.bar(df.index, df.business, width=0.4, align='edge', label='Business')\n",
    "\n",
    "plt.xlabel('Counties')\n",
    "plt.ylabel('Total Installed Capacity (kW)')\n",
    "plt.title('Total Installed Capacity (Combined) Segmented by Business / Not Business')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=.25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the data to monthly frequency and calculate month-to-month change\n",
    "# Resampling to month-end frequency\n",
    "monthly_data = enefit_dict['client'].set_index('date').installed_capacity.resample('M').last()  \n",
    "\n",
    "# Calculate the absolute increase\n",
    "monthly_data.name = monthly_data.name.strip()\n",
    "month_to_month_change = monthly_data.diff()\n",
    "\n",
    "# Calculate the average increase\n",
    "avg_month_to_month_change = month_to_month_change.mean()\n",
    "\n",
    "print(f\"Average month-on-month increase in Installed Capacity: {avg_month_to_month_change:.2f}kW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['client'].set_index('date').installed_capacity.resample('D').sum()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Installed Capacity (kW)')\n",
    "ax.set_title('Total Daily Installed Capacity Over Time')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    x='date', y='installed_capacity', data=enefit_dict['client']\n",
    ")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Installed Capacity')\n",
    "plt.title('Time Series Plot of Installed Capacity (kW)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider if installed capacity can be modeled using time series forecasting.\n",
    "\n",
    "The time series for installed capaity has a clear trend. However, seasonality is not clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = STL(enefit_dict['client'].set_index('date').installed_capacity, period=365).fit()\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, ncols=1, sharex=True, figsize=(10,8))\n",
    "\n",
    "ax1.plot(decomposition.observed, color=deep_colors[0])\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "ax2.plot(decomposition.trend, color=deep_colors[1])\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "ax3.plot(decomposition.seasonal, color=deep_colors[2])\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "ax4.plot(decomposition.resid, color=deep_colors[3])\n",
    "ax4.set_ylabel('Residuals')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Daily Installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = STL(enefit_dict['client'].set_index('date').installed_capacity.resample('D').sum(), period=365).fit()\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, ncols=1, sharex=True, figsize=(10,8))\n",
    "\n",
    "ax1.plot(decomposition.observed, color=deep_colors[0])\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "ax2.plot(decomposition.trend, color=deep_colors[1])\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "ax3.plot(decomposition.seasonal, color=deep_colors[2])\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "ax4.plot(decomposition.resid, color=deep_colors[3])\n",
    "ax4.set_ylabel('Residuals')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for stationarity:\n",
    "\n",
    "Due to the nature of the data, we'll resample the data to add up or average all records for a particular date. Then we'll use first order differencing to make time series stationary if it is not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Daily Installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['client'].set_index('date').installed_capacity.resample('D').sum()\n",
    "ad_fuller_result = adfuller(df)\n",
    "\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = np.diff(df, n=1)\n",
    "\n",
    "ad_fuller_result = adfuller(df_diff)\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing for Autocorrelation & Partial Autocorrelation: \n",
    "\n",
    "Visually, there seems to be no lags after the first lag for both autoregressive and moving average metrics in the installed capacity time series. This implies that the series is a random walk. \n",
    "\n",
    "A random walk is a process in which there is an equal chance of going up or down by a random number. Random walks often expose long periods where a positive or negative trend can be observed. They are also often accompanied by sudden changes in direction.\n",
    "\n",
    "We can only use naive forecasting methods with random walks. This means that the installed capacity cannot be modeled using an AutoRegressive Integrated Moving Average (ARIMA) model. Naive forecasting methods include mean, last value, last seasonal value, drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "plot_acf(df_diff, lags=10, ax=ax1)\n",
    "plot_pacf(df_diff, lags=10, ax=ax2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a random walk, we can only forecast using naive methods such as mean, last value, last seasonal value, etc. We'll consider using linear regression to model time and serial dependence for forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_frame()\n",
    "df['time'] = np.arange(len(df.index)) # set time steps from index\n",
    "df['lag_1'] = df.installed_capacity.shift(1) # First lag\n",
    "df = df.reindex(columns=['installed_capacity', 'time', 'lag_1'])\n",
    "\n",
    "df.installed_capacity = df.installed_capacity.astype(float)\n",
    "df.lag_1 = df.lag_1.astype(float)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 7))\n",
    "\n",
    "ax1.plot(df.time, df.installed_capacity, color=deep_colors[0])\n",
    "sns.regplot(\n",
    "    x='time', y='installed_capacity', data=df,\n",
    "    ci=None, scatter_kws=dict(color=deep_colors[1]), ax=ax1\n",
    ")\n",
    "ax1.set_title('Time Plot of Installed Capacity')\n",
    "\n",
    "sns.regplot(\n",
    "    x='lag_1', y='installed_capacity', data=df,\n",
    "    ci=None, scatter_kws=dict(color=deep_colors[0]), ax=ax2\n",
    ")\n",
    "ax2.set_aspect('equal')\n",
    "ax2.set_title('Lag Plot of Installed Capacity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'installed_capacity ~ time'\n",
    "model = smf.ols(formula, data=df)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'installed_capacity ~ lag_1'\n",
    "model = smf.ols(formula, data=df)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models created are approximately: \n",
    "- `Installed Capacity = 104.8 * time + 6234`\n",
    "- `Installed Capacity = 1 * lag_1 + -203.77`\n",
    "\n",
    "We can use these formulas to predict future values. We'll use these models along with naive forecasts to predict future installed capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_forecast(\n",
    "        df: pd.DataFrame, train_len: int, horizon: int,\n",
    "        window: int, method: str, pdq=(0,0,0)\n",
    ") -> list:\n",
    "\n",
    "    total_len = train_len + horizon\n",
    "\n",
    "    if method == 'mean':\n",
    "        pred_mean = []\n",
    "\n",
    "        for i in range(train_len, total_len, window):\n",
    "            # mean = np.mean(df[:i].values)\n",
    "            mean = np.mean(df[:i])\n",
    "            pred_mean.extend(mean for _ in range(window))\n",
    "\n",
    "        return pred_mean\n",
    "\n",
    "    elif method == 'last':\n",
    "        pred_last_value = []\n",
    "\n",
    "        for i in range(train_len, total_len, window):\n",
    "            # last_value = df[:i].iloc[-1].values[0]\n",
    "            last_value = df[:i].iloc[-1]#.values[0]\n",
    "            pred_last_value.extend(last_value for _ in range(window))\n",
    "\n",
    "        return pred_last_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.installed_capacity.loc[:'2023-04-30']\n",
    "df_test = df.installed_capacity.loc['2023-05-01':]\n",
    "\n",
    "train_len = len(df_train)\n",
    "horizon = len(df_test)\n",
    "window = 1\n",
    "\n",
    "pred_mean = rolling_forecast(df['installed_capacity'], train_len, horizon, window, 'mean')\n",
    "pred_last_value = rolling_forecast(df['installed_capacity'], train_len, horizon, window, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df.installed_capacity.loc[:'2023-04-30']\n",
    "y_test = df.installed_capacity.loc['2023-05-01':]\n",
    "\n",
    "X_time_train = df.loc[:'2023-04-30', ['time']]\n",
    "X_time_test = df.loc['2023-05-01':, ['time']]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_time_train, y_train)\n",
    "pred_timestep = pd.Series(model.predict(X_time_test), index=X_time_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lag_train = df.loc[:'2023-04-30', ['lag_1']].dropna()\n",
    "X_lag_test = df.loc['2023-05-01':, ['lag_1']].dropna()\n",
    "y_train_lag, X_lag_train = y_train.align(X_lag_train, join='inner')\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_lag_train, y_train_lag)\n",
    "pred_lag = pd.Series(model.predict(X_lag_test), index=X_lag_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.to_frame().copy()\n",
    "df_test.loc[:, 'pred_mean'] = pred_mean\n",
    "df_test = df_test.copy()\n",
    "df_test.loc[:, 'pred_last_value'] = pred_last_value\n",
    "df_test = df_test.copy()\n",
    "df_test.loc[:, 'pred_timestep'] = pred_timestep\n",
    "df_test = df_test.copy()\n",
    "df_test.loc[:, 'pred_lag'] = pred_lag\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df_train.loc['2023-04':])\n",
    "ax.plot(df_test['installed_capacity'], 'b-', label='actual')\n",
    "ax.plot(df_test['pred_mean'], 'g:', label='mean')\n",
    "ax.plot(df_test['pred_last_value'], 'r-.', label='last')\n",
    "ax.plot(df_test['pred_timestep'], 'k--', label='timestep')\n",
    "ax.plot(df_test['pred_lag'], 'y--', label='lag_1')\n",
    "\n",
    "ax.legend(loc=2, fontsize='small')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Installed Capacity')\n",
    "ax.set_title('Installed Capacity with Forecasts')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Daily Installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = STL(enefit_dict['client'].set_index('date').installed_capacity.resample('D').mean(), period=365).fit()\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, ncols=1, sharex=True, figsize=(10,8))\n",
    "\n",
    "ax1.plot(decomposition.observed, color=deep_colors[0])\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "ax2.plot(decomposition.trend, color=deep_colors[1])\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "ax3.plot(decomposition.seasonal, color=deep_colors[2])\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "ax4.plot(decomposition.resid, color=deep_colors[3])\n",
    "ax4.set_ylabel('Residuals')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for Stationarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['client'].set_index('date').installed_capacity.resample('D').mean()\n",
    "ad_fuller_result = adfuller(df)\n",
    "\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = np.diff(df, n=1)\n",
    "\n",
    "ad_fuller_result = adfuller(df_diff)\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing for Autocorrelation & Partial Autocorrelation: \n",
    "\n",
    "Visually, there seems to be no lags after the first lag for both autoregressive and moving average metrics in the installed capacity time series. This implies that the series is a random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "plot_acf(df_diff, lags=10, ax=ax1)\n",
    "plot_pacf(df_diff, lags=10, ax=ax2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.to_frame()\n",
    "df['time'] = np.arange(len(df.index)) # set time steps from index\n",
    "df['lag_1'] = df.installed_capacity.shift(1) # First lag\n",
    "df = df.reindex(columns=['installed_capacity', 'time', 'lag_1'])\n",
    "\n",
    "df.installed_capacity = df.installed_capacity.astype(float)\n",
    "df.lag_1 = df.lag_1.astype(float)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 7))\n",
    "\n",
    "ax1.plot(df.time, df.installed_capacity, color=deep_colors[0])\n",
    "sns.regplot(\n",
    "    x='time', y='installed_capacity', data=df,\n",
    "    ci=None, scatter_kws=dict(color=deep_colors[1]), ax=ax1\n",
    ")\n",
    "ax1.set_title('Time Plot of Installed Capacity')\n",
    "\n",
    "sns.regplot(\n",
    "    x='lag_1', y='installed_capacity', data=df,\n",
    "    ci=None, scatter_kws=dict(color=deep_colors[0]), ax=ax2\n",
    ")\n",
    "ax2.set_aspect('equal')\n",
    "ax2.set_title('Lag Plot of Installed Capacity')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'installed_capacity ~ time'\n",
    "model = smf.ols(formula, data=df)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'installed_capacity ~ lag_1'\n",
    "model = smf.ols(formula, data=df)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models created are approximately: \n",
    "- `Installed Capacity = 1.46 * time + 984.24`\n",
    "- `Installed Capacity = 1 * lag_1 + -5.36`\n",
    "\n",
    "We can use these formulas to predict future values. We'll use these models along with naive forecasts to predict future installed capacity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.installed_capacity.loc[:'2023-04-30']\n",
    "df_test = df.installed_capacity.loc['2023-05-01':]\n",
    "\n",
    "train_len = len(df_train)\n",
    "horizon = len(df_test)\n",
    "window = 1\n",
    "\n",
    "pred_mean = rolling_forecast(df['installed_capacity'], train_len, horizon, window, 'mean')\n",
    "pred_last_value = rolling_forecast(df['installed_capacity'], train_len, horizon, window, 'last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df.installed_capacity.loc[:'2023-04-30']\n",
    "y_test = df.installed_capacity.loc['2023-05-01':]\n",
    "\n",
    "X_time_train = df.loc[:'2023-04-30', ['time']]\n",
    "X_time_test = df.loc['2023-05-01':, ['time']]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_time_train, y_train)\n",
    "pred_timestep = pd.Series(model.predict(X_time_test), index=X_time_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lag_train = df.loc[:'2023-04-30', ['lag_1']].dropna()\n",
    "X_lag_test = df.loc['2023-05-01':, ['lag_1']].dropna()\n",
    "y_train_lag, X_lag_train = y_train.align(X_lag_train, join='inner')\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_lag_train, y_train_lag)\n",
    "pred_lag = pd.Series(model.predict(X_lag_test), index=X_lag_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.to_frame().copy()\n",
    "df_test.loc[:, 'pred_mean'] = pred_mean\n",
    "df_test = df_test.copy()\n",
    "df_test.loc[:, 'pred_last_value'] = pred_last_value\n",
    "df_test = df_test.copy()\n",
    "df_test.loc[:, 'pred_timestep'] = pred_timestep\n",
    "df_test = df_test.copy()\n",
    "df_test.loc[:, 'pred_lag'] = pred_lag\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df_train.loc['2023-04':])\n",
    "ax.plot(df_test['installed_capacity'], 'b-', label='actual')\n",
    "ax.plot(df_test['pred_mean'], 'g:', label='mean')\n",
    "ax.plot(df_test['pred_last_value'], 'r-.', label='last')\n",
    "ax.plot(df_test['pred_timestep'], 'k--', label='timestep')\n",
    "ax.plot(df_test['pred_lag'], 'y--', label='lag_1')\n",
    "\n",
    "ax.legend(loc=2, fontsize='small')\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Installed Capacity')\n",
    "ax.set_title('Installed Capacity with Forecasts')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Consumption Points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_order = enefit_dict['client'].groupby(by='county_map').agg({'eic_count':'sum'}).sort_values(by='eic_count', ascending=False).index.values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.barplot(\n",
    "    data=enefit_dict['client'],\n",
    "    x='eic_count',\n",
    "    y='county_map',\n",
    "    estimator='sum',\n",
    "    orient='h',\n",
    "    order=plot_order,\n",
    "    ax=ax\n",
    ")\n",
    "ax.grid(alpha=.25)\n",
    "\n",
    "ax.set_xlabel('Total Consumption Points')\n",
    "ax.set_ylabel('Counties')\n",
    "ax.set_title('Total Consumption Points across Counties')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all counties, consumption points are higher for non-business users than for business users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['client'].groupby(by=['county_map', 'is_business']).eic_count.sum().unstack().rename(columns={0:'not_business', 1:'business'})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df.index, df.not_business, width=0.4, align='center', label='Not Business')\n",
    "plt.bar(df.index, df.business, width=0.4, align='edge', label='Business')\n",
    "\n",
    "plt.xlabel('Counties')\n",
    "plt.ylabel('Total Consumption Points')\n",
    "plt.title('Total Consumption Points Segmented by Business / Not Business')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(alpha=.25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "g = sns.catplot(\n",
    "    data=enefit_dict['client'],\n",
    "    kind=\"bar\",\n",
    "    orient='h',\n",
    "    y='county_map',\n",
    "    x='eic_count',\n",
    "    hue='is_business',\n",
    "    col='product_type_map',\n",
    "    col_wrap=2,\n",
    "    height=4,\n",
    "    estimator=sum\n",
    ")\n",
    "\n",
    "g.set_axis_labels('County', 'Consumption Points')\n",
    "g.set_titles('Product Type: {col_name}')\n",
    "\n",
    "new_labels = ['Non-business', 'Business']\n",
    "for ax in g.axes.flat:\n",
    "    handles, _ = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles, new_labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "# Remove the previous legend\n",
    "g._legend.remove()\n",
    "\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Total Consumption Points by Product Type & Business Segments')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['client'].query(\n",
    "    'product_type_map==\"General service\"'\n",
    ").groupby(by=['county_map', 'is_business']).eic_count.sum().unstack().rename(columns={0:'not_business', 1:'business'})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df.index, df.not_business, width=0.4, align='center', label='Not Business')\n",
    "plt.bar(df.index, df.business, width=0.4, align='edge', label='Business')\n",
    "\n",
    "plt.xlabel('Counties')\n",
    "plt.ylabel('Total Consumption Points')\n",
    "plt.title('Total Consumption Points (General service) Segmented by Business / Not Business')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=.25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['client'].query(\n",
    "    'product_type_map==\"Combined\"'\n",
    ").groupby(by=['county_map', 'is_business']).eic_count.sum().unstack().rename(columns={0:'not_business', 1:'business'})\n",
    "df['not_business'] = 0\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df.index, df.not_business, width=0.4, align='center', label='Not Business')\n",
    "plt.bar(df.index, df.business, width=0.4, align='edge', label='Business')\n",
    "\n",
    "plt.xlabel('Counties')\n",
    "plt.ylabel('Total Consumption Points')\n",
    "plt.title('Total Consumption Points (Combined) Segmented by Business / Not Business')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=.25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_data = enefit_dict['client'].set_index('date').eic_count.resample('M').last()\n",
    "\n",
    "# Calculate the absolute increase\n",
    "monthly_data.name = monthly_data.name.strip()\n",
    "month_to_month_change = monthly_data.diff()\n",
    "\n",
    "# Calculate the average increase\n",
    "avg_month_to_month_change = month_to_month_change.mean()\n",
    "print(f\"Average month-on-month increase in Consumption Points: {avg_month_to_month_change:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['client'].set_index('date').eic_count.resample('D').sum()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(df)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Consumption Points')\n",
    "ax.set_title('Total Daily Consumption Points Over Time')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(\n",
    "    x='date', y='eic_count', data=enefit_dict['client']\n",
    ")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Consumption Points')\n",
    "plt.title('Time Series Plot of Consumption Points')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider if eic count can be modeled using time series forecasting:\n",
    "\n",
    "The time series for eic count has a clear trend. However, seasonality is not clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = STL(enefit_dict['client'].set_index('date').eic_count, period=365).fit()\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(nrows=4, ncols=1, sharex=True, figsize=(10,8))\n",
    "\n",
    "ax1.plot(decomposition.observed, color=deep_colors[0])\n",
    "ax1.set_ylabel('Observed')\n",
    "\n",
    "ax2.plot(decomposition.trend, color=deep_colors[1])\n",
    "ax2.set_ylabel('Trend')\n",
    "\n",
    "ax3.plot(decomposition.seasonal, color=deep_colors[2])\n",
    "ax3.set_ylabel('Seasonal')\n",
    "\n",
    "ax4.plot(decomposition.resid, color=deep_colors[3])\n",
    "ax4.set_ylabel('Residuals')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total EIC Count:\n",
    "\n",
    "First order differencing to make the time series stationary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['client'].set_index('date').eic_count.resample('D').sum()\n",
    "ad_fuller_result = adfuller(df)\n",
    "\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = np.diff(df, n=1)\n",
    "ad_fuller_result = adfuller(df_diff)\n",
    "\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EIC Count is also a random walk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "plot_acf(df_diff, lags=10, ax=ax1)\n",
    "plot_pacf(df_diff, lags=10, ax=ax2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average EIC Count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['client'].set_index('date').eic_count.resample('D').mean()\n",
    "ad_fuller_result = adfuller(df)\n",
    "\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = np.diff(df, n=1)\n",
    "ad_fuller_result = adfuller(df_diff)\n",
    "\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "plot_acf(df_diff, lags=10, ax=ax1)\n",
    "plot_pacf(df_diff, lags=10, ax=ax2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Electricity Prices**\n",
    "\n",
    "The features in this dataset are:\n",
    "* origin_date: The date when the day-ahead prices became available.\n",
    "* forecast_date: The date when the forecast prices should be relevant.\n",
    "* euros_per_mwh: The price of electricity on the day ahead markets in euros per megawatt hour.\n",
    "* data_block_id: All rows sharing the same `data_block_id` will be available at the same forecast time. This is a function of what information is available when forecasts are actually made, at 11 AM each morning. For example, if the forecast weather `data_block_id` for predictions made on October 31st is 100 then the historic weather data_block_id for October 31st will be 101 as the historic weather data is only actually available the next day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enefit_dict['electricity_prices'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enefit_dict['electricity_prices'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(121)\n",
    "enefit_dict['electricity_prices'].euros_per_mwh.plot.hist(\n",
    "    bins=30, \n",
    "    title='Distribution of Electricity Prices',\n",
    ")\n",
    "plt.grid(alpha=.5)\n",
    "\n",
    "plt.subplot(122)\n",
    "enefit_dict['electricity_prices'].euros_per_mwh.plot.box(title='Box Plot of Electricity Prices')\n",
    "plt.grid(alpha=.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25% of the dataset is greater than the 75th percentile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enefit_dict['electricity_prices'].query('euros_per_mwh > 200').shape[0] / enefit_dict['electricity_prices'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a single large outlier record. It is for `data_block_id` 351:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enefit_dict['electricity_prices'].query('euros_per_mwh > 2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cost_full = enefit_dict['electricity_prices'].query('data_block_id==351').euros_per_mwh.mean()\n",
    "avg_cost_filtered = enefit_dict['electricity_prices'].query('data_block_id==351 & euros_per_mwh < 2000').euros_per_mwh.mean()\n",
    "euro_symbol = '\\u20AC'\n",
    "\n",
    "print(f'The average electricity cost with outlier is {euro_symbol}{avg_cost_full:,.2f}, while the average cost without outlier is {euro_symbol}{avg_cost_filtered:,.2f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(\n",
    "    enefit_dict['electricity_prices'].forecast_date,\n",
    "    enefit_dict['electricity_prices'].euros_per_mwh, \n",
    "    linestyle='-', linewidth=1\n",
    ")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Electricity Price')\n",
    "plt.title('Electricity Prices Over Time')\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(\n",
    "    enefit_dict['electricity_prices'].query('euros_per_mwh < 2000').forecast_date,\n",
    "    enefit_dict['electricity_prices'].query('euros_per_mwh < 2000').euros_per_mwh,\n",
    "    linestyle='-', linewidth=1\n",
    ")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Electricity Price')\n",
    "plt.title('Electricity Prices Over Time (No Outliers)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_mean = enefit_dict['electricity_prices'].query('euros_per_mwh < 2000').set_index('forecast_date').euros_per_mwh.resample('M').mean().interpolate()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(211)\n",
    "plt.plot(\n",
    "    monthly_mean.index, monthly_mean, marker='o', linestyle='-', linewidth=1.5\n",
    ")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Mean Electricity Price')\n",
    "plt.title('Average Monthly Cost of Electricity Over Time (No Outliers)')\n",
    "plt.grid(alpha=.5)\n",
    "\n",
    "plt.subplot(212)\n",
    "monthly_mean = enefit_dict['electricity_prices'].query('euros_per_mwh < 2000').euros_per_mwh.groupby(enefit_dict['electricity_prices'].forecast_date.dt.month).mean()\n",
    "\n",
    "month_mapping = {\n",
    "    1: 'Jan', 2: 'Feb', 3: 'March', 4: 'April',\n",
    "    5: 'May', 6: 'June', 7: 'July', 8: 'Aug',\n",
    "    9: 'Sept', 10: 'Oct', 11: 'Nov', 12: 'Dec'\n",
    "}\n",
    "monthly_mean.index = monthly_mean.index.map(month_mapping)\n",
    "plt.plot(\n",
    "    monthly_mean.index, monthly_mean, marker='o', linestyle='-', linewidth=1.5\n",
    ")\n",
    "plt.xlabel('Months')\n",
    "plt.ylabel('Mean Electricity Price')\n",
    "plt.title('Average Electricity Price Grouped by Month (No Outliers)')\n",
    "plt.grid(alpha=.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Electricity Costs are on average highest in the summer, with the peak occurring in the summer of 2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enefit_dict['electricity_prices']['forecast_month'] = enefit_dict['electricity_prices'].forecast_date.dt.month\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(\n",
    "    x='forecast_month', y='euros_per_mwh', data=enefit_dict['electricity_prices']\n",
    ")\n",
    "# plt.grid(alpha=.5)\n",
    "plt.title('Energy Prices by Month (‚Ç¨)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_data = enefit_dict['electricity_prices'].set_index('forecast_date').euros_per_mwh.resample('M').last()  \n",
    "monthly_data.name = monthly_data.name.strip()\n",
    "month_to_month_change = monthly_data.diff()\n",
    "avg_month_to_month_change = month_to_month_change.mean()\n",
    "euro_symbol = '\\u20AC'\n",
    "\n",
    "print(f\"Average month-on-month change in Electricity Cost: {euro_symbol}{avg_month_to_month_change:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost of electricity is generally in the same range except for a significant spike in August 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(\n",
    "    x='forecast_date', y='euros_per_mwh', \n",
    "    data=enefit_dict['electricity_prices'],\n",
    "    estimator='sum', color=deep_colors[0], \n",
    "    linewidth=1.2, alpha=.8, label='Total Price', \n",
    ")\n",
    "sns.lineplot(\n",
    "    x='forecast_date', y='euros_per_mwh', \n",
    "    data=enefit_dict['electricity_prices'],\n",
    "    estimator='mean', color=deep_colors[1], \n",
    "    linewidth=1.2, alpha=.4, label='Average Price'\n",
    ")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Electricity Cost')\n",
    "plt.title('Time Series Plot of Electricity Cost')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=.3)\n",
    "# plt.legend().remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Series Plot without Outlier record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(\n",
    "    x='forecast_date', y='euros_per_mwh', \n",
    "    data=enefit_dict['electricity_prices'].query('euros_per_mwh < 2000'),\n",
    "    estimator='sum', linewidth=1.2, color=deep_colors[0], \n",
    "    alpha=.8, label='Total Price'\n",
    ")\n",
    "sns.lineplot(\n",
    "    x='forecast_date', y='euros_per_mwh', \n",
    "    data=enefit_dict['electricity_prices'].query('euros_per_mwh < 2000'),\n",
    "    estimator='mean', linewidth=1.2, color=deep_colors[1], \n",
    "    alpha=.4, label='Average Price'\n",
    ")\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Electricity Cost')\n",
    "plt.title('Time Series Plot of Electricity Cost (Without Outliers)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=.3)\n",
    "# plt.legend().remove()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Series Decomposition:\n",
    "\n",
    "Decompose the time series into its trend, seasonality, and residual components to better understand underlying patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24H Period\n",
    "decomposition = STL(enefit_dict['electricity_prices'].set_index('forecast_date').euros_per_mwh, period=24).fit()\n",
    "observed = decomposition.observed\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "# Plot the original time series\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(411)\n",
    "plt.plot(observed, label='Observed', color=deep_colors[0])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Original Time Series')\n",
    "\n",
    "# Plot the trend component\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend', color=deep_colors[1])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Trend Component')\n",
    "\n",
    "# Plot the seasonal component\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal, label='Seasonal', color=deep_colors[2])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Seasonal Component')\n",
    "\n",
    "# Plot the residual component\n",
    "plt.subplot(414)\n",
    "plt.plot(residual, label='Residual', color=deep_colors[3])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Residual Component')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 365D Period\n",
    "decomposition = STL(enefit_dict['electricity_prices'].set_index('forecast_date').euros_per_mwh, period=365*24).fit()\n",
    "observed2 = decomposition.observed\n",
    "trend2 = decomposition.trend\n",
    "seasonal2 = decomposition.seasonal\n",
    "residual2 = decomposition.resid\n",
    "\n",
    "# Plot the original time series\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(411)\n",
    "plt.plot(observed2, label='Observed', color=deep_colors[0])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Original Time Series')\n",
    "\n",
    "# Plot the trend component\n",
    "plt.subplot(412)\n",
    "plt.plot(trend2, label='Trend', color=deep_colors[1])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Trend Component')\n",
    "\n",
    "# Plot the seasonal component\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal2, label='Seasonal', color=deep_colors[2])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Seasonal Component')\n",
    "\n",
    "# Plot the residual component\n",
    "plt.subplot(414)\n",
    "plt.plot(residual2, label='Residual', color=deep_colors[3])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Residual Component')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30D Period\n",
    "decomposition = STL(enefit_dict['electricity_prices'].set_index('forecast_date').euros_per_mwh, period=30*24).fit()\n",
    "observed3 = decomposition.observed\n",
    "trend3 = decomposition.trend\n",
    "seasonal3 = decomposition.seasonal\n",
    "residual3 = decomposition.resid\n",
    "\n",
    "# Plot the original time series\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(411)\n",
    "plt.plot(observed3, label='Observed', color=deep_colors[0])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Original Time Series')\n",
    "\n",
    "# Plot the trend component\n",
    "plt.subplot(412)\n",
    "plt.plot(trend3, label='Trend', color=deep_colors[1])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Trend Component')\n",
    "\n",
    "# Plot the seasonal component\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal3, label='Seasonal', color=deep_colors[2])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Seasonal Component')\n",
    "\n",
    "# Plot the residual component\n",
    "plt.subplot(414)\n",
    "plt.plot(residual3, label='Residual', color=deep_colors[3])\n",
    "plt.legend(loc='upper left')\n",
    "plt.title('Residual Component')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing Trend Component:\n",
    "\n",
    "There are erratic movements in the trend which might suggest volatility, however, the trendline is flat, indicating that there is no overall trend or movement in the price of electricity. Prices remain constant with no discernible change or variation over the observed time period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12,8), sharex=True)\n",
    "\n",
    "ax1.plot(trend, label='Trend', color=deep_colors[1])\n",
    "# Fit a linear regression trend-line\n",
    "x_values = pd.to_numeric(trend.index) / 10**9\n",
    "coefficients = np.polyfit(x_values, trend.fillna(0), 1)\n",
    "slope, intercept = coefficients\n",
    "trendline_values = slope * x_values + intercept\n",
    "trendline_dates = pd.to_datetime(x_values.astype(int) * 10**9)\n",
    "\n",
    "ax1.plot(trendline_dates, trendline_values, label='Trendline', linestyle='--', color='red')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.set_title('Trend Component (24H)')\n",
    "\n",
    "\n",
    "ax2.plot(trend2, label='Trend', color=deep_colors[1])\n",
    "# Fit a linear regression trend-line\n",
    "x_values = pd.to_numeric(trend2.index) / 10**9\n",
    "coefficients = np.polyfit(x_values, trend2.fillna(0), 1)\n",
    "slope, intercept = coefficients\n",
    "trendline_values = slope * x_values + intercept\n",
    "trendline_dates = pd.to_datetime(x_values.astype(int) * 10**9)\n",
    "\n",
    "ax2.plot(trendline_dates, trendline_values, label='Trendline', linestyle='--', color='red')\n",
    "# ax2.legend(loc='upper left')\n",
    "ax2.set_title('Trend Component (1Y)')\n",
    "\n",
    "\n",
    "ax3.plot(trend3, label='Trend', color=deep_colors[1])\n",
    "# Fit a linear regression trend-line\n",
    "x_values = pd.to_numeric(trend3.index) / 10**9\n",
    "coefficients = np.polyfit(x_values, trend3.fillna(0), 1)\n",
    "slope, intercept = coefficients\n",
    "trendline_values = slope * x_values + intercept\n",
    "trendline_dates = pd.to_datetime(x_values.astype(int) * 10**9)\n",
    "\n",
    "ax3.plot(trendline_dates, trendline_values, label='Trendline', linestyle='--', color='red')\n",
    "# ax3.legend(loc='upper left')\n",
    "ax3.set_title('Trend Component (30D)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing Seasonal Component:\n",
    "\n",
    "When we drill down into the seasonal component, we find repetitive and predictitve patterns occurring at fixed intervals within the data. Seasonality represents the systematic, periodic fluctuations that repeat over specific time periods (e.g., daily, weekly, monthly, yearly).\n",
    "\n",
    "For electricity prices, we have repetitive weekly fluctuations throughout the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2022\n",
    "months_to_select = [1]  \n",
    "\n",
    "selected_data = seasonal[(seasonal.index.year == year) & (seasonal.index.month.isin(months_to_select))]\n",
    "selected_data2 = seasonal2[(seasonal2.index.year == year) & (seasonal2.index.month.isin(months_to_select))]\n",
    "selected_data3 = seasonal3[(seasonal3.index.year == year) & (seasonal3.index.month.isin(months_to_select))]\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(15, 12), sharex=True)\n",
    "\n",
    "ax1.plot(selected_data, label='Seasonal', color=deep_colors[2])\n",
    "ax1.set_title(f'24H Seasonal Trends for {year} - Jan')\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "ax2.plot(selected_data2, label='Seasonal', color=deep_colors[2])\n",
    "ax2.set_title(f'1Y Seasonal Trends for {year} - Jan')\n",
    "ax2.set_xlabel('Date')\n",
    "\n",
    "ax3.plot(selected_data2, label='Seasonal', color=deep_colors[2])\n",
    "ax3.set_title(f'30D Seasonal Trends for {year} - Jan')\n",
    "ax3.set_xlabel('Date')\n",
    "\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing the amplitude or magnitude of the seasonal fluctuations:\n",
    "\n",
    "The range and standard deviation of the seasonal component are not as high, indicating that the amplitude are not as high and there is not significant variability fo data points from the mean.\n",
    "\n",
    "However, the Coefficient of variation is significantly large indicating that the mean of seasonality is small relative to the variability or dispersion of the data points (or the spread or variability among the data points is large relative to that mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing amplitude using statistical measures\n",
    "seasonal_amplitude = seasonal.max() - seasonal.min()\n",
    "std_dev = seasonal.std()\n",
    "coefficient_of_variation = std_dev / seasonal.mean()\n",
    "amplitude_mean = seasonal.mean()\n",
    "amplitude_median = seasonal.median()\n",
    "amplitude_variance = seasonal.var()\n",
    "amplitude_percentile_95 = np.percentile(seasonal, 95)\n",
    "amplitude_percentile_5 = np.percentile(seasonal, 5)\n",
    "\n",
    "print(\"24H Seasonal Component\")\n",
    "print(f\"Amplitude (Range) of Seasonal Component: {seasonal_amplitude:.2f}\")\n",
    "print(f\"Mean of Seasonal Component: {amplitude_mean}\")\n",
    "print(f\"Median of Seasonal Component: {amplitude_median:.2f}\")\n",
    "print(f\"Variance of Seasonal Component: {amplitude_variance:.2f}\")\n",
    "print(f\"Standard Deviation of Seasonal Component: {std_dev:.2f}\")\n",
    "print(f\"Coefficient of Variation of Seasonal Component: {coefficient_of_variation:.4f}\")\n",
    "print(f\"95th Percentile of Seasonal Component: {amplitude_percentile_95:.2f}\")\n",
    "print(f\"5th Percentile of Seasonal Component: {amplitude_percentile_5:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing amplitude using statistical measures\n",
    "seasonal_amplitude = seasonal2.max() - seasonal2.min()\n",
    "std_dev = seasonal2.std()\n",
    "coefficient_of_variation = std_dev / seasonal2.mean()\n",
    "amplitude_mean = seasonal2.mean()\n",
    "amplitude_median = seasonal2.median()\n",
    "amplitude_variance = seasonal2.var()\n",
    "amplitude_percentile_95 = np.percentile(seasonal2, 95)\n",
    "amplitude_percentile_5 = np.percentile(seasonal2, 5)\n",
    "\n",
    "print(\"1Y Seasonal Component\")\n",
    "print(f\"Amplitude (Range) of Seasonal Component: {seasonal_amplitude:.2f}\")\n",
    "print(f\"Mean of Seasonal Component: {amplitude_mean}\")\n",
    "print(f\"Median of Seasonal Component: {amplitude_median:.2f}\")\n",
    "print(f\"Variance of Seasonal Component: {amplitude_variance:.2f}\")\n",
    "print(f\"Standard Deviation of Seasonal Component: {std_dev:.2f}\")\n",
    "print(f\"Coefficient of Variation of Seasonal Component: {coefficient_of_variation:.4f}\")\n",
    "print(f\"95th Percentile of Seasonal Component: {amplitude_percentile_95:.2f}\")\n",
    "print(f\"5th Percentile of Seasonal Component: {amplitude_percentile_5:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing amplitude using statistical measures\n",
    "seasonal_amplitude = seasonal3.max() - seasonal3.min()\n",
    "std_dev = seasonal3.std()\n",
    "coefficient_of_variation = std_dev / seasonal3.mean()\n",
    "amplitude_mean = seasonal3.mean()\n",
    "amplitude_median = seasonal3.median()\n",
    "amplitude_variance = seasonal3.var()\n",
    "amplitude_percentile_95 = np.percentile(seasonal3, 95)\n",
    "amplitude_percentile_5 = np.percentile(seasonal3, 5)\n",
    "\n",
    "print(\"30D Seasonal Component\")\n",
    "print(f\"Amplitude (Range) of Seasonal Component: {seasonal_amplitude:.2f}\")\n",
    "print(f\"Mean of Seasonal Component: {amplitude_mean}\")\n",
    "print(f\"Median of Seasonal Component: {amplitude_median:.2f}\")\n",
    "print(f\"Variance of Seasonal Component: {amplitude_variance:.2f}\")\n",
    "print(f\"Standard Deviation of Seasonal Component: {std_dev:.2f}\")\n",
    "print(f\"Coefficient of Variation of Seasonal Component: {coefficient_of_variation:.4f}\")\n",
    "print(f\"95th Percentile of Seasonal Component: {amplitude_percentile_95:.2f}\")\n",
    "print(f\"5th Percentile of Seasonal Component: {amplitude_percentile_5:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the amplitude of seasonal fluctuations across different time periods or seasonal cycles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = enefit_dict['electricity_prices'].set_index('forecast_date').euros_per_mwh.asfreq('H').bfill()\n",
    "\n",
    "result = seasonal_decompose(data, model='additive') \n",
    "\n",
    "period = 24\n",
    "num_cycles = len(data) // period\n",
    "seasonal_amplitudes = []\n",
    "for i in range(num_cycles):\n",
    "    start_idx = i * period\n",
    "    end_idx = min((i + 1) * period, len(data))\n",
    "    seasonal_component = result.seasonal[start_idx:end_idx]\n",
    "    amplitude = seasonal_component.max() - seasonal_component.min()\n",
    "    cv = (seasonal_component.std() / seasonal_component.mean()) * 100\n",
    "    seasonal_amplitudes.append({'Period': i + 1, 'Amplitude': amplitude, 'CV_24H': cv})\n",
    "amplitudes_df_24 = pd.DataFrame(seasonal_amplitudes)\n",
    "\n",
    "period = 365 * 24\n",
    "num_cycles = len(data) // period\n",
    "seasonal_amplitudes = []\n",
    "for i in range(num_cycles):\n",
    "    start_idx = i * period\n",
    "    end_idx = min((i + 1) * period, len(data))\n",
    "    seasonal_component = result.seasonal[start_idx:end_idx]\n",
    "    amplitude = seasonal_component.max() - seasonal_component.min()\n",
    "    cv = (seasonal_component.std() / seasonal_component.mean()) * 100\n",
    "    seasonal_amplitudes.append({'Period': i + 1, 'Amplitude': amplitude, 'CV_365D': cv})\n",
    "amplitudes_df_365 = pd.DataFrame(seasonal_amplitudes)\n",
    "\n",
    "period = 30 * 24\n",
    "num_cycles = len(data) // period\n",
    "seasonal_amplitudes = []\n",
    "for i in range(num_cycles):\n",
    "    start_idx = i * period\n",
    "    end_idx = min((i + 1) * period, len(data))\n",
    "    seasonal_component = result.seasonal[start_idx:end_idx]\n",
    "    amplitude = seasonal_component.max() - seasonal_component.min()\n",
    "    cv = (seasonal_component.std() / seasonal_component.mean()) * 100\n",
    "    seasonal_amplitudes.append({'Period': i + 1, 'Amplitude': amplitude, 'CV_30D': cv})\n",
    "amplitudes_df_30 = pd.DataFrame(seasonal_amplitudes)\n",
    "\n",
    "amplitudes_df = amplitudes_df_24.merge(amplitudes_df_365, how='left', on=['Period', 'Amplitude'])\n",
    "amplitudes_df = amplitudes_df.merge(amplitudes_df_30, how='left', on=['Period', 'Amplitude'])\n",
    "amplitudes_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing Residual Component:\n",
    "\n",
    "Analyzing the residual component resulting from a seasonal decomposition helps to understand the unexplained variation in the time series after accounting for the trend, seasonality, and other identified components. It is crucial to assess the goodness-of-fit of the decomposition model and to detect any remaining patterns or information that the model didn't capture.\n",
    "\n",
    "The distribution of the residual plot appears to be approximately normal and the autocorrelation plot shows a flat line with no significant spikes. This indicates that residuals are centered and have consistent variability. \n",
    "\n",
    "The flat autocorrelation also indicates the absence of significant autocorrelation at different lags, which suggests that the residuals are not correlated at different time lags, indicating randomness or lack of systematic patterns.\n",
    "\n",
    "The normal distribution and absence of significant autocorrelation in residuals suggest that the seasonal decomposition model adequately captures the underlying trend, seasonality, and other components present in the time series data for electricty prices. This implies goodness of fit and model adequacy.\n",
    "\n",
    "The lack of autocorrelation further implies that any remaining variation in the data captured by the residuals is random noise or unexplained variability, rather than systematic patterns or trends.\n",
    "\n",
    "We can therefore use the decomposition model to forecast future observation as the model adequately captures the data's variability.\n",
    "\n",
    "The best model is the 365D model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize residuals - 24H\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "residual.plot(title='Residuals Time Plot')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "residual.plot(kind='hist', bins=20, title='Residuals Distribution')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "residual.plot(kind='kde', title='Residuals Density Plot')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "pd.plotting.autocorrelation_plot(residual)\n",
    "plt.title('Autocorrelation Plot of Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize residuals - 365D\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "residual2.plot(title='Residuals Time Plot')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "residual2.plot(kind='hist', bins=20, title='Residuals Distribution')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "residual2.plot(kind='kde', title='Residuals Density Plot')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "pd.plotting.autocorrelation_plot(residual2)\n",
    "plt.title('Autocorrelation Plot of Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize residuals - 30D\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(2, 2, 1)\n",
    "residual3.plot(title='Residuals Time Plot')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "residual3.plot(kind='hist', bins=20, title='Residuals Distribution')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "residual3.plot(kind='kde', title='Residuals Density Plot')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "pd.plotting.autocorrelation_plot(residual3)\n",
    "plt.title('Autocorrelation Plot of Residuals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Analysis\n",
    "print(\"Summary Statistics of Residuals - 24H:\")\n",
    "print(residual.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary Statistics of Residuals - 365D:\")\n",
    "print(residual2.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Summary Statistics of Residuals - 30D:\")\n",
    "print(residual3.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use linear regression to moddel electrictiy prices, we find that the time index is a poor predictor of price. However, 1H and 24H lags as well as 24H MA and 30D MA are better predictors of electricity price using a linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = enefit_dict['electricity_prices'].set_index('forecast_date').euros_per_mwh.asfreq('H').bfill()\n",
    "data = data.to_frame()\n",
    "data['time'] = np.arange(len(data.index))\n",
    "data['lag_1'] = data.euros_per_mwh.shift(1)\n",
    "data['lag_12'] = data.euros_per_mwh.shift(12)\n",
    "data['lag_24'] = data.euros_per_mwh.shift(24)\n",
    "data['lag_30d'] = data.euros_per_mwh.shift(30*24)\n",
    "data['lag_365d'] = data.euros_per_mwh.shift(365*24)\n",
    "data['MA_24'] = data.euros_per_mwh.rolling(window=24, center=True, min_periods=12).mean()\n",
    "data['MA_30'] = data.euros_per_mwh.rolling(window='30D', center=True, min_periods=24*15).mean()\n",
    "data['MA_365'] = data.euros_per_mwh.rolling(window='365D', center=True, min_periods=24*183).mean()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'euros_per_mwh ~ time'\n",
    "model = smf.ols(formula, data=data)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'euros_per_mwh ~ lag_1'\n",
    "model = smf.ols(formula, data=data)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'euros_per_mwh ~ lag_12'\n",
    "model = smf.ols(formula, data=data)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'euros_per_mwh ~ lag_24'\n",
    "model = smf.ols(formula, data=data)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'euros_per_mwh ~ lag_30d'\n",
    "model = smf.ols(formula, data=data)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'euros_per_mwh ~ lag_365d'\n",
    "model = smf.ols(formula, data=data)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'euros_per_mwh ~ MA_24'\n",
    "model = smf.ols(formula, data=data)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'euros_per_mwh ~ MA_30'\n",
    "model = smf.ols(formula, data=data)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'euros_per_mwh ~ MA_365'\n",
    "model = smf.ols(formula, data=data)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Series Modeling:\n",
    "\n",
    "The time series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['electricity_prices'].set_index('forecast_date').euros_per_mwh.asfreq('H').bfill()\n",
    "ad_fuller_result = adfuller(df)\n",
    "\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In testing for autocorrelation and partial autocorrelation, we find that significant coefficients exist beyond the first lag for both plots. This means we have a time series that can be modeled usign \n",
    "ARIMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "plot_acf(df, lags=10, ax=ax1)\n",
    "plot_pacf(df, lags=10, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the stationary time series, we'll use an ARIMA model to determine the optimum AR(_p_) and MA(_q_) values for the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_ARIMA(\n",
    "        # The order_list parameter now includes p, q orders. \n",
    "        endog: Union[pd.Series, list], \n",
    "        # exog: Union[pd.Series, list], # useful for a SARIMAX model\n",
    "        order_list: list, \n",
    "        d: int, \n",
    "        # D: int, s: int # useful for a SARIMAX model\n",
    "        ) -> pd.DataFrame:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        results = []\n",
    "        \n",
    "        # Loop over all unique ARIMA(p,d,q) models, \n",
    "        # fit them, and store the AICs.\n",
    "        for order in notebook.tqdm(order_list):\n",
    "            try: \n",
    "                model = SARIMAX(\n",
    "                    endog, \n",
    "                    # exog,\n",
    "                    order=(order[0], d, order[1]),\n",
    "                    # seasonal_order=(order[2], D, order[3], s),\n",
    "                    simple_differencing=False).fit(disp=False)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "            aic = model.aic\n",
    "            results.append([order, aic])\n",
    "            \n",
    "        result_df = pd.DataFrame(results)\n",
    "        result_df.columns = ['(p,q)', 'AIC']\n",
    "        \n",
    "        #Sort in ascending order, lower AIC is better\n",
    "        result_df = result_df.sort_values(by='AIC', ascending=True).reset_index(drop=True)\n",
    "        \n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = range(0, 5, 1)\n",
    "qs = range(0, 5, 1)\n",
    "d = 0\n",
    "\n",
    "ARIMA_order_list = list(product(ps, qs))\n",
    "ARIMA_result_df = optimize_ARIMA(df, ARIMA_order_list, d)\n",
    "ARIMA_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = range(0, 5, 1)\n",
    "qs = range(0, 5, 1)\n",
    "d = 1\n",
    "\n",
    "ARIMA_order_list = list(product(ps, qs))\n",
    "ARIMA_result_df = optimize_ARIMA(df, ARIMA_order_list, d)\n",
    "ARIMA_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is based on data that is recorded hourly. We'll resample to daily records and check the AICs for the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Daily Price:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for stationarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['electricity_prices'].set_index('forecast_date').euros_per_mwh.resample('D').sum()\n",
    "\n",
    "ad_fuller_result = adfuller(df)\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = np.diff(df, n=1)\n",
    "ad_fuller_result = adfuller(df_diff)\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for autocorrelation and partial autocorrelation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "plot_acf(df, lags=10, ax=ax1)\n",
    "plot_pacf(df, lags=10, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "plot_acf(df_diff, lags=10, ax=ax1)\n",
    "plot_pacf(df_diff, lags=10, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model data and select best AIC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = range(0, 10, 1)\n",
    "qs = range(0, 10, 1)\n",
    "d = 1\n",
    "\n",
    "ARIMA_order_list = list(product(ps, qs))\n",
    "ARIMA_result_df = optimize_ARIMA(df, ARIMA_order_list, d)\n",
    "ARIMA_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Daily Price:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['electricity_prices'].set_index('forecast_date').euros_per_mwh.resample('D').mean()\n",
    "\n",
    "ad_fuller_result = adfuller(df)\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = np.diff(df, n=1)\n",
    "ad_fuller_result = adfuller(df_diff)\n",
    "print(f'ADF Statistic: {ad_fuller_result[0]}')\n",
    "print(f'p-value: {ad_fuller_result[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "plot_acf(df, lags=10, ax=ax1)\n",
    "plot_pacf(df, lags=10, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "plot_acf(df_diff, lags=10, ax=ax1)\n",
    "plot_pacf(df_diff, lags=10, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = range(0, 10, 1)\n",
    "qs = range(0, 10, 1)\n",
    "d = 1\n",
    "\n",
    "ARIMA_order_list = list(product(ps, qs))\n",
    "ARIMA_result_df = optimize_ARIMA(df, ARIMA_order_list, d)\n",
    "ARIMA_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is the one on the data that has been resampled to daily records and averaged.\n",
    "\n",
    "Fit based on best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = enefit_dict['electricity_prices'].set_index('forecast_date').euros_per_mwh.resample('D').mean()\n",
    "\n",
    "d = 1\n",
    "SARIMAX_model = SARIMAX(\n",
    "    endog=df, \n",
    "    order=(ARIMA_result_df.iloc[0,0][0], d, ARIMA_result_df.iloc[0,0][1]),\n",
    "    simple_differencing=False\n",
    "    )\n",
    "SARIMAX_model_fit = SARIMAX_model.fit(disp=False)\n",
    "print(SARIMAX_model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARIMAX_model_fit.plot_diagnostics(figsize=(10,8))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = SARIMAX_model_fit.resid\n",
    "lb_df = acorr_ljungbox(residuals, np.arange(1, 11, 1))\n",
    "\n",
    "lb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Electricity prices can be modeled using ARIMA. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
