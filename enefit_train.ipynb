{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6f8ba1b67c1b53",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Enefit - Predict Energy Behavior of Prosumers\n",
    "\n",
    "The challenge in this competition is to predict the amount of electricity produced and consumed by Estonian energy customers who have installed solar panels. The dataset includes weather data, the relevant energy prices, and records of the installed photovoltaic capacity.\n",
    "\n",
    "This is a forecasting competition using the time series API.\n",
    "\n",
    "**Description**\n",
    "\n",
    "The number of prosumers is rapidly increasing, and solving the problems of energy imbalance and their rising costs is vital. If left unaddressed, this could lead to increased operational costs, potential grid instability, and inefficient use of energy resources. If this problem were effectively solved, it would significantly reduce the imbalance costs, improve the reliability of the grid, and make the integration of prosumers into the energy system more efficient and sustainable. Moreover, it could potentially incentivize more consumers to become prosumers, knowing that their energy behavior can be adequately managed, thus promoting renewable energy production and use.\n",
    "\n",
    "**About us**\n",
    "\n",
    "Enefit is one of the biggest energy companies in Baltic region. As experts in the field of energy, we help customers plan their green journey in a personal and flexible manner as well as implement it by using environmentally friendly energy solutions.\n",
    "At present, Enefit is attempting to solve the imbalance problem by developing internal predictive models and relying on third-party forecasts. However, these methods have proven to be insufficient due to their low accuracy in forecasting the energy behavior of prosumers. The shortcomings of these current methods lie in their inability to accurately account for the wide range of variables that influence prosumer behavior, leading to high imbalance costs. By opening up the challenge to the world's best data scientists through the Kaggle platform, Enefit aims to leverage a broader pool of expertise and novel approaches to improve the accuracy of these predictions and consequently reduce the imbalance and associated costs.\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "Submissions are evaluated on the Mean Absolute Error (MAE) between the predicted return and the observed target. The formula is given by:\n",
    "\n",
    "𝑀𝐴𝐸=1𝑛∑𝑖=1𝑛|𝑦𝑖−𝑥𝑖|\n",
    "\n",
    "Where:\n",
    "* 𝑛 is the total number of data points.\n",
    "* 𝑦𝑖 is the predicted value for data point i.\n",
    "* 𝑥𝑖 is the observed value for data point i.\n",
    "\n",
    "**Submitting**\n",
    "\n",
    "You must submit to this competition using the provided python time-series API, which ensures that models do not peek forward in time. To use the API, follow the template in this [notebook](https://www.kaggle.com/code/sohier/enefit-basic-submission-demo).\n",
    "\n",
    "**Timeline**\n",
    "\n",
    "This is a future data prediction competition with an active training phase and a second period where selected submissions will be evaluated against future ground truth data.\n",
    "\n",
    "*Training Timeline*\n",
    "\n",
    "* November 1, 2023 - Start Date.\n",
    "* January 24, 2024 - Entry Deadline. You must accept the competition rules before this date in order to compete.\n",
    "* January 24, 2024 - Team Merger Deadline. This is the last day participants may join or merge teams.\n",
    "* January 31, 2024 - Final Submission Deadline.\n",
    "\n",
    "All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.\n",
    "\n",
    "*Prediction Timeline:*\n",
    "\n",
    "Starting after the final submission deadline there will be periodic updates to the leaderboard to reflect future data updates that will be evaluated against selected submissions. We anticipate 1-3 interim updates before the final evaluation.\n",
    "\n",
    "* April 30, 2024 - Competition End Date\n",
    "\n",
    "**Prizes**\n",
    "\n",
    "* 1st Place - $ 15,000\n",
    "* 2nd Place - $ 10,000\n",
    "* 3rd Place - $ 8,000\n",
    "* 4th Place - $ 7,000\n",
    "* 5th Place - $ 5,000\n",
    "* 6th Place - $ 5,000\n",
    "\n",
    "**Code Requirements**\n",
    "\n",
    "Submissions to this competition must be made through Notebooks. In order for the \"Submit\" button to be active after a commit, the following conditions must be met:\n",
    "\n",
    "* CPU Notebook <= 9 hours run-time\n",
    "* GPU Notebook <= 9 hours run-time\n",
    "* Internet access disabled\n",
    "* Freely & publicly available external data is allowed, including pre-trained models\n",
    "* Submission file must be named submission.csv and be generated by the API.\n",
    "\n",
    "Please see the [Code Competition FAQ](https://www.kaggle.com/docs/competitions#notebooks-only-FAQ) for more information on how to submit. And review the [code debugging doc](https://www.kaggle.com/code-competition-debugging) if you are encountering submission errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff606311",
   "metadata": {},
   "source": [
    "### Load Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime as dt\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "import opendatasets as od\n",
    "import kaggle\n",
    "import zipfile\n",
    "import io\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, STL\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from tqdm import notebook\n",
    "from itertools import product\n",
    "from typing import Union\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7641e3d3",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e968947c0cf9181",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['client.csv',\n",
       " 'county_id_to_name_map.json',\n",
       " 'electricity_prices.csv',\n",
       " 'enefit/__init__.py',\n",
       " 'enefit/competition.cpython-310-x86_64-linux-gnu.so',\n",
       " 'example_test_files/client.csv',\n",
       " 'example_test_files/electricity_prices.csv',\n",
       " 'example_test_files/forecast_weather.csv',\n",
       " 'example_test_files/gas_prices.csv',\n",
       " 'example_test_files/historical_weather.csv',\n",
       " 'example_test_files/revealed_targets.csv',\n",
       " 'example_test_files/sample_submission.csv',\n",
       " 'example_test_files/test.csv',\n",
       " 'forecast_weather.csv',\n",
       " 'gas_prices.csv',\n",
       " 'historical_weather.csv',\n",
       " 'public_timeseries_testing_util.py',\n",
       " 'train.csv',\n",
       " 'weather_station_to_county_mapping.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_files_in_zip(zip_file_path):\n",
    "    zip_files = list()\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        file_list = zip_ref.namelist()\n",
    "        for file in file_list:\n",
    "            zip_files.append(file)\n",
    "    return zip_files\n",
    "\n",
    "zip_file_path = 'predict-energy-behavior-of-prosumers.zip'\n",
    "\n",
    "enefit_files = list_files_in_zip(zip_file_path)\n",
    "enefit_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8dfc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_from_zip(zip_file_path, csv_file_name):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        with zip_ref.open(csv_file_name) as file:\n",
    "            df = pd.read_csv(io.TextIOWrapper(file))\n",
    "            return df\n",
    "\n",
    "def read_json_from_zip(zip_file_path, json_file_name):\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        with zip_ref.open(json_file_name) as file:\n",
    "            data = json.load(file)\n",
    "            df = pd.DataFrame(data, index=range(len(data)))\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e82577",
   "metadata": {},
   "outputs": [],
   "source": [
    "enefit_dict = dict()\n",
    "keys = [\n",
    "    'client', 'county_id_to_name_map', \n",
    "    'electricity_prices', 'forecast_weather',\n",
    "    'gas_prices', 'historical_weather', \n",
    "    'train', 'weather_station_to_county_mapping'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0d5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in keys:\n",
    "    if key + '.csv' in enefit_files:\n",
    "        csv_file_name = key + '.csv'\n",
    "        enefit_dict[key] = read_csv_from_zip(zip_file_path, csv_file_name)\n",
    "    elif key + '.json' in enefit_files:\n",
    "        json_file_name = key + '.json'\n",
    "        enefit_dict[key] = read_json_from_zip(zip_file_path, json_file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b93d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(df):\n",
    "    date_cols = ['date', 'datetime', 'forecast_date', 'origin_date', 'forecast_datetime', 'origin_datetime']\n",
    "    for col in df.columns:\n",
    "        if col in date_cols:\n",
    "            df[col] = pd.to_datetime(df[col])\n",
    "    return df\n",
    "\n",
    "for key in keys:\n",
    "    enefit_dict[key] = clean_date(enefit_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc818bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          HARJUMAA\n",
       "1           HIIUMAA\n",
       "2       IDA-VIRUMAA\n",
       "3          JÄRVAMAA\n",
       "4         JÕGEVAMAA\n",
       "5     LÄÄNE-VIRUMAA\n",
       "6          LÄÄNEMAA\n",
       "7          PÄRNUMAA\n",
       "8          PÕLVAMAA\n",
       "9          RAPLAMAA\n",
       "10         SAAREMAA\n",
       "11         TARTUMAA\n",
       "12          UNKNOWN\n",
       "13         VALGAMAA\n",
       "14      VILJANDIMAA\n",
       "15          VÕRUMAA\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enefit_dict['county_id_to_name_map'] = enefit_dict['county_id_to_name_map'].iloc[0].T\n",
    "enefit_dict['county_id_to_name_map']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd844bcb",
   "metadata": {},
   "source": [
    "### Create Training Data\n",
    "\n",
    "**Train**\n",
    "\n",
    "The features in this dataset are:\n",
    "* county: An ID code for the county.\n",
    "* is_business: Boolean for whether or not the prosumer is a business.\n",
    "* product_type: ID code with the following mapping of codes to contract types: {0: \"Combined\", 1: \"Fixed\", 2: \"General service\", 3: \"Spot\"}.\n",
    "* target: The consumption or production amount for the relevant segment for the hour. The segments are defined by the county, is_business, and product_type.\n",
    "* is_consumption: Boolean for whether or not this row's target is consumption or production.\n",
    "* datetime: The Estonian time in EET (UTC+2) / EEST (UTC+3). It describes the start of the 1-hour period on which target is given.\n",
    "* data_block_id: All rows sharing the same data_block_id will be available at the same forecast time. This is a function of what information is available when forecasts are actually made, at 11 AM each morning. For example, if the forecast weather data_block_id for predictins made on October 31st is 100 then the historic weather data_block_id for October 31st will be 101 as the historic weather data is only actually available the next day.\n",
    "* row_id: A unique identifier for the row.\n",
    "* prediction_unit_id: A unique identifier for the county, is_business, and product_type combination. New prediction units can appear or disappear in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c9420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enefit_dict['train'].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
